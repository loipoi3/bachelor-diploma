%!TEX root = ../thesis.tex
% створюємо розділ
\chapter{Підготовка до проведення дослідження}
\label{chap:theory}

В даному розділі знаходиться огляд основних інструментів та методів аналізу та попередньої обробки даних, також ми зазначимо використані інструменти та ресурси для моделювання.

\section{Використані інструменти та ресурси}

В якості мови програмування було вибрано Python v3.11~\cite{ct18}, це ефективна та гнучка мова програмування, для розв'язання задач машинного навчання, для якої створено велику кількість бібіліотек та ресурсів, які дозволяють ефективно розв'язувати задачі, включаючи задачі бінарної та багатокласової класифікації табличних даних та картинок. Основними бібліотеками для створення моделей були бібліотеки Deap v1.4~\cite{ct19} та scikit-learn v1.4~\cite{ct20}. Обидві бібліотеки надають документацію, невеликі навчальні посібники та приклади для пришвидшення побудови моделей.

Бібліотека Deap --- це спеціалізована бібліотека для створення еволюційних алгоритмів. Ця бібліотека має реалізовані рішення для різних задач, таких як генетичне програмування, еволюційні стратегії, генетичні алгоритми та багато інших. Вона забезпечує зручний інтерфейс для налаштування та запуску еволюційних експериментів, надаючи широкий набір інструментів для маніпуляції популяціями, відбору, кросинговеру та мутацій. Основними елементами бібліотеки Deap є індивідуми, популяції, фітнес-функції, оператори генетичних алгоритмів, такі як, відбір, кросинговер та мутація. Ця бібліотека також дозволяє налаштовувати багато параметрів, таких як розмір популяції, кількість поколінь, ймовірності мутацій та кросинговеру, що робить її дуже гнучкою для різних задач. Вона підтримує паралельні обчислення, що значно прискорює процес еволюційного пошуку оптимальних рішень. В даному дослідженні буде використовуватись бібліотека Deap для реалізації $(1+\lambda)$-EA with GP encodings, що дозволяє досліджувати ефективність та керованість цього алгоритму в контексті задачі класифікації. Зокрема, ми будемо використовувати такі оператори, як турнірний відбір та одноточкову мутацію. Крім того, буде проведено аналіз впливу різних гіперпараметрів, таких як, значення $\lambda$ та глибина дерева, а також множини термінальних та внутрішніх вузлів, на якість розв'язків та швидкість конвергенції алгоритму.

Бібліотека scikit-learn --- це популярна бібліотека для машинного навчання, яка надає великий набір інструментів для задач класифікації, регресії, кластеризації, зниження розмірності та попередньої обробки даних. Вона забезпечує простий і уніфікований інтерфейс для побудови та оцінки моделей машинного навчання, що дозволяє швидко розробляти і тестувати різні алгоритми. Основні компоненти бібліотеки scikit-learn включають реалізовані алгоритми для класифікації, регресії, кластеризації та зниження розмірності, а також методи для попередньої обробки даних. В даному дослідженні бібліотека scikit-learn буде використовуватись для підготовки даних, вибору ознак, побудови та оцінки моделей класифікації. Зокрема, ми будемо використовувати стандартні підходи до попередньої обробки даних, такі як масштабування ознак, зниження розмірності та розділення даних на тренувальну та тестову вибірки. Побудова моделей буде здійснюватись з використанням алгоритму MLP. Результати класифікації будуть оцінюватись за допомогою метрик, таких як accuracy, precision, recall та f1-score. Це дозволить порівняти ефективність різних підходів та обрати найкращий алгоритм для задачі класифікації.

Також були використані наступні бібліотеки: pandas~\cite{ct21} -- для завантаження та попередньої обробки даних, optuna~\cite{ct22} -- для оптимізації гіперпараметрів моделей, torch~\cite{ct23} та torchvision~\cite{ct24} -- для обробки картинок та створення ембідінгів з моделей.

Проаналізувавши різноманітні сервіси, які надають доступ до даних, в якості вебресурсу з даними ми використовуємо вебсайт \href{https://www.kaggle.com/datasets}{https://www.kaggle.com/datasets}. Kaggle -- це платформа для змагань з машинного навчання, яка також надає великий каталог відкритих наборів даних для різноманітних задач, включаючи класифікацію, регресію та кластеризацію. Набори даних на Kaggle часто добре документовані та попередньо оброблені, що дозволяє швидко приступити до експериментів.

\section{Попередня обробка даних}

В даній роботі використовувалися наступніі набори даниих: 

-- Pima Indians Diabetes Database (посилання: \href{https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database/data}{https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database/data}) -- це набір даних, який часто використовується для задач класифікації в області біомедичних досліджень. Цей датасет був зібраний Національним інститутом діабету, шлункових і ниркових захворювань США. Набір даних містить інформацію про жінок з племені Піма, що проживають в Арізоні, та включає показники здоров'я, які можуть впливати на розвиток діабету. Датасет складається з 768 зразків, кожен з яких має 8 вхідних ознаки і два вихідних класи, які вказують на наявність або відсутність діабету. Всі ознаки числові, що дозволяє легко використовувати їх у машинному навчанні. Датасет складається з наступних ознак: Pregnancies -- кількість вагітностей у жінки; Glucose -- рівень глюкози у плазмі крові через 2 години після навантажувального тесту; Blood Pressure -- діастолічний артеріальний тиск; Skin Thickness -- товщина шкірної складки трицепса; Insulin -- рівень інсуліну у сироватці крові; BMI -- індекс маси тіла; Diabetes Pedigree Function -- функція родоводу діабету (враховує генетичну спадковість); Age -- вік пацієнта; цільова змінна: Outcome -- наявність діабету (0 - відсутній, 1 - наявний).
Цей датасет є добре збалансованим з точки зору наявності та відсутності діабету серед обстежених жінок, що робить його придатним для задач класифікації. Попередня обробка даних для цього датасету зазвичай включає масштабування ознак, обробку пропущених значень (якщо такі є) та розділення даних на тренувальну та тестову вибірки для подальшого навчання і оцінки моделей.








\chapconclude{\ref{chap:theory}}

Наприкінці розділу знову наводяться коротенькі підсумки.