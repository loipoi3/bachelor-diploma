%!TEX root = ../thesis.tex
% створюємо розділ
\chapter{Підготовка до проведення дослідження}
\label{chap:theory}

В даному розділі знаходиться огляд основних інструментів та методів аналізу та попередньої обробки даних, також ми зазначимо використані інструменти та ресурси для моделювання.

\section{Використані інструменти та ресурси}

В якості мови програмування було вибрано Python v3.11~\cite{ct18}, це ефективна та гнучка мова програмування, для розв'язання задач ML, для якої створено велику кількість бібіліотек та ресурсів, які дозволяють ефективно розв'язувати задачі, включаючи задачі бінарної та багатокласової класифікації табличних даних та зображень. Основними бібліотеками для створення моделей були бібліотеки Deap v1.4~\cite{ct19} та scikit-learn v1.4~\cite{ct20}. Обидві бібліотеки надають документацію, невеликі навчальні посібники та приклади для пришвидшення побудови моделей.

Бібліотека Deap~\cite{ct19} --- це спеціалізована бібліотека для створення EA. Ця бібліотека має реалізовані рішення для різних задач, таких як GP, еволюційні стратегії, генетичні алгоритми та багато інших. Вона забезпечує зручний інтерфейс для налаштування та запуску еволюційних експериментів, надаючи широкий набір інструментів для маніпуляції популяціями, відбору, кросинговеру та мутацій. Основними елементами бібліотеки Deap~\cite{ct19} є індивіди, популяції, фітнес-функції, оператори генетичних алгоритмів, такі як, відбір, кросинговер та мутація. Ця бібліотека також дозволяє налаштовувати багато параметрів, таких як розмір популяції, кількість поколінь, ймовірності мутацій та кросинговеру, що робить її дуже гнучкою для різних задач. Вона підтримує паралельні обчислення, що значно прискорює процес еволюційного пошуку оптимальних рішень. В даному дослідженні буде використовуватись бібліотека Deap~\cite{ct19} для реалізації $(1+\lambda)$-EA with GP encodings, що дозволяє досліджувати ефективність та керованість цього алгоритму в контексті задачі класифікації. Зокрема, ми будемо використовувати такі оператори, як турнірний відбір та одноточкову мутацію. Крім того, буде проведено аналіз впливу різних гіперпараметрів, таких як, значення $\lambda$ та глибина дерева на якість розв'язків та швидкість конвергенції алгоритму.

Бібліотека scikit-learn~\cite{ct20} --- це популярна бібліотека для ML, яка надає великий набір інструментів для задач класифікації, регресії, кластеризації, зниження розмірності та попередньої обробки даних. Вона забезпечує простий і уніфікований інтерфейс для побудови та оцінки моделей ML, що дозволяє швидко розробляти і тестувати різні алгоритми. Основні компоненти бібліотеки scikit-learn~\cite{ct20} включають реалізовані алгоритми для класифікації, регресії, кластеризації та зниження розмірності, а також методи для попередньої обробки даних. В даному дослідженні бібліотека scikit-learn~\cite{ct20} буде використовуватись для підготовки даних, вибору ознак, побудови та оцінки моделей класифікації. Зокрема, ми будемо використовувати стандартні підходи до попередньої обробки даних, такі як масштабування ознак, зниження розмірності та розділення даних на тренувальну та тестову вибірки. Побудова моделей буде здійснюватись з використанням алгоритму MLP~\cite{ct26}. Результати класифікації будуть оцінюватись за допомогою метрик, таких як accuracy~\cite{ct6}, precision~\cite{ct6}, recall~\cite{ct7} та f1-score~\cite{ct8}. Це дозволить порівняти ефективність різних підходів та обрати найкращий алгоритм для задачі класифікації.

Також були використані наступні бібліотеки: pandas~\cite{ct21} -- для завантаження та попередньої обробки даних, optuna~\cite{ct22} -- для оптимізації гіперпараметрів моделей, torch~\cite{ct23} та torchvision~\cite{ct24} -- для обробки зображень та створення з них ембедінгів.

Проаналізувавши різноманітні сервіси, які надають доступ до даних, в якості вебресурсу з даними ми використовуємо вебсайт \href{https://www.kaggle.com/datasets}{https://www.kaggle.com/datasets}. Kaggle -- це платформа для змагань з ML, яка також надає великий каталог відкритих наборів даних для різноманітних задач, включаючи класифікацію, регресію та кластеризацію. Набори даних на kaggle часто добре документовані та попередньо оброблені, що дозволяє швидко приступити до експериментів.

\section{Опис використаних наборів даних} \label{sec:data-description}

В даній роботі використовувалися наступні набори даниих: 

-- Pima Indians Diabetes Database~\cite{ct30} -- це набір даних, який використовується для задач бінарної класифікації табличних даних в області біомедичних досліджень. Цей датасет був зібраний Національним інститутом діабету, шлункових і ниркових захворювань США. Набір даних містить інформацію про жінок з племені Піма, що проживають в Арізоні, та включає показники здоров'я, які можуть впливати на розвиток діабету. Датасет складається з 768 зразків, кожен з яких має 8 вхідних ознак і два вихідних класи, які вказують на наявність або відсутність діабету. Всі ознаки числові, що дозволяє легко використовувати їх у ML. Датасет складається з наступних ознак: Pregnancies -- кількість вагітностей у жінки; Glucose -- рівень глюкози у плазмі крові через 2 години після навантажувального тесту; Blood Pressure -- діастолічний артеріальний тиск; Skin Thickness -- товщина шкірної складки трицепса; Insulin -- рівень інсуліну у сироватці крові; BMI -- індекс маси тіла; Diabetes Pedigree Function -- функція родоводу діабету (враховує генетичну спадковість); Age -- вік пацієнта; цільова змінна: Outcome -- наявність діабету (0 - відсутній, 1 - наявний). Цей датасет має збалансовані класи.

-- Human Activity Recognition with Smartphones~\cite{ct31} -- це набір даних, який використовується для задач багатокласової класифікації табличних даних в області розпізнавання людської діяльності. Цей датасет був зібраний за допомогою вбудованих акселерометрів та гіроскопів смартфонів, що носили на поясі 30 учасників. Дані записувалися під час виконання різних фізичних активностей, включаючи ходьбу, підйом та спуск по сходах, сидіння, стояння та лежання. Датасет складається з 10 299 зразків, кожен з яких має 562 вхідні ознаки, що представляють різні статистичні та перетворені значення з сигналів акселерометра і гіроскопа, такі як середнє значення, стандартне відхилення, максимальні та мінімальні значення, а також частотні перетворення. Всі ознаки числові. Датасет складається з наступних ознак: Body Acceleration -- лінійне прискорення тіла в осях X, Y та Z; Total Acceleration -- загальне прискорення тіла в осях X, Y та Z; Body Gyroscope -- кутова швидкість тіла в осях X, Y та Z; Jerk Signals -- похідні лінійного прискорення та кутової швидкості; Magnitude of these three-dimensional signals -- величина сигналів прискорення та гіроскопа; Frequency domain features -- перетворені у частотну область сигнали за допомогою швидкого перетворення Фур'є; цільова змінна: Activity -- тип фізичної активності, виконуваної учасником (наприклад, walking, walking upstairs, walking downstairs, sitting, standing, laying). Цей датасет є збалансованим і добре підходить для задач класифікації, оскільки містить різноманітні фізичні активності.

-- Chest X-Ray Images (Pneumonia)~\cite{ct32} -- це набір даних, який використовується для задач бінарної та багатокласової класифікації зображень у медичних дослідженнях. Цей датасет містить рентгенівські знімки грудної клітки пацієнтів з пневмонією (вірусною або бактеріальною) та без неї. Дані були зібрані для сприяння розвитку моделей ML, здатних автоматично виявляти пневмонію на рентгенівських знімках. Датасет складається з 5 840 зображень, які розділені на дві категорії: Train та Test. Кожна категорія містить зображення, позначені як <<Pneumonia>> або <<Normal>>, або якщо розглядати задачу, як багатокласову класифікацію, то <<Pneumonia>> розділяється на <<Virus>> та <<Bacteria>>. Цей датасет надає великі можливості для досліджень у сфері медичної діагностики за допомогою глибинного навчання, дозволяючи розробляти моделі, які можуть автоматично ідентифікувати захворювання на основі рентгенівських знімків.

Ці три набори даних представляють різноманітні задачі класифікації, включаючи бінарну класифікацію табличних даних, багатокласову класифікацію табличних даних, бінарну класифікацію зображень та багатокласову класифікацію зображень. Це дозволяє комплексно оцінити ефективність методів і моделей у різних доменах застосування ML.

\section{Вплив Expressive Encodings на ефективність класифікаційних алгоритмів}

У цьому розділі ми розглянемо вплив експресивних кодувань на ефективність класифікаційних алгоритмів. Основою для даного аналізу є стаття <<Simple Genetic Operators are Universal Approximators of Probability Distributions (and other Advantages of Expressive Encodings)>> авторів Elliot Meyerson, Xin Qiu та Risto Miikkulainen~\cite{ct25}, яка досліджує можливості генетичних алгоритмів завдяки їхнім expressive encodings (за формальним означенням можна звернутися до~\cite[Definition 1, стор. 3]{ct25}). В цій статті описуються переваги використання expressive encodings у EA. Головна ідея полягає в тому, що такі encodings дозволяють EA ефективно знаходити рішення у складних середовищах, дозволяючи простим генетичним операторам~\cite[підрозділ 2.2.3, стор. 3]{ct25} апроксимувати будь-який розподіл ймовірностей фенотипів потомства~\cite[розділ 2.1, стор. 2]{ct25}. До переваг expressive encodings також відносяться: прискорення конвергенції, тобто такі encodings можуть забезпечити надекспоненційне прискорення конвергенції, а також зменшення потреби в ручному налаштуванні, завдяки expressive encodings немає потреби у складному ручному налаштуванні операторів для кожної окремої задачі. В даній статті наводяться теореми 4.2~\cite[Theorem 4.2]{ct25} та 4.4~\cite[Theorem 4.4]{ct25}, в яких йдеться про те, що GP є expressive encodings для одноточкової мутації та що MLP з сигмоїдною функцією активації також є expressive encodings для одноточкової мутації. Автори статті розглядають алгоритм $(1+\lambda)$-EA with GP encodings (псевдокод алгоритму можна знайти~\cite[Appendix B, стор. 12]{ct25}) для вирішення проблем DFC~\cite[Problem 1, стор. 6]{ct25}, RFC~\cite[Problem 2, стор. 7]{ct25} та LBAP~\cite[Problem 3, стор. 7]{ct25}. Саме цим дослідженням ми надихнулись та порівняли методи MLP with gradient descent, MLP with single-point mutation та $(1+\lambda)$-EA with GP encodings для задач бінарної та багатокласової класифікації табличних даних та зображень.

\chapconclude{\ref{chap:theory}}

У цьому розділі було детально описано інструменти, які були використані для підготовки та проведення дослідження. Розглянуто основні бібліотеки Python, які використовувалися для моделювання та аналізу даних, а також наведено опис трьох наборів даних, які були використані для задач класифікації. Було обрано Python v3.11 як мову програмування завдяки її ефективності та гнучкості. Основними бібліотеками, які використовувалися для створення моделей, були Deap v1.4 та scikit-learn v1.4. Бібліотека Deap забезпечує зручний інтерфейс для налаштування та запуску еволюційних експериментів, що дозволяє реалізувати EA, такі як $(1+\lambda)$-EA with GP encodings. Бібліотека scikit-learn надає великий набір інструментів для попередньої обробки даних, побудови та оцінки моделей класифікації. Також використовувалися бібліотеки pandas, optuna, torch та torchvision для завантаження та обробки даних та оптимізації гіперпараметрів. Були використані три різні набори даних, які представляють різноманітні задачі класифікації: Pima Indians Diabetes Database -- набір даних для бінарної класифікації табличних даних в області біомедичних досліджень; Human Activity Recognition with Smartphones -- набір даних для багатокласової класифікації табличних даних, зібраний за допомогою акселерометрів та гіроскопів смартфонів; Chest X-Ray Images (Pneumonia) -- набір даних для бінарної та багатокласової класифікації зображень у медичних дослідженнях. Було розглянуто вплив expressive encodings на ефективність класифікаційних алгоритмів. Це дозволить здійснити порівняння та оцінку ефективності різних підходів у наступному розділі роботи. Додамо, що усі методи тренувалися на комп'ютері, який має наступні обчислювальні ресурси: процесор -- AMD Ryzen 5 3600 6-Core Processor, оперативна пам'ять -- 32GB DDR4.