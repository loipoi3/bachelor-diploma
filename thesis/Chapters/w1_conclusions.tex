%!TEX root = ../thesis.tex
% створюємо Висновки до всієї роботи
У ході даної роботи ми розглянули теоретичні відомості про задачі класифікації, а саме бінарну та багатокласову класифікацію, а також різні методи їх вирішення. Нами було розглянуто класичні статистичні методи, методи машинного навчання, методи глибинного навчання та генетичні алгоритми, зокрема алгоритм $(1+\lambda)$-EA with GP encodings, для вирішення задач класифікації. Додатково ми розглянули детально процес навчання моделей класифікації та метрики, які використовуються для оцінювання ефективності таких методів.

Також ми розглянули процес попередньої обробки даних, пошуку оптимальних гіперпараметрів для якого ми використали байєсівську оптимізацію та провели експерименти, які продемонстрували переваги та недоліки кожного з розглянутих методів. 

Було встановлено, що для задач, де найважливішим показником є швидкість навчання, краще використовувати MLP with gradient descent, оскільки він в середньому виявився на 97.835\% швидше за модель MLP with single-point mutation та на 99.994\% швидше за модель $(1+\lambda)$-EA with GP encoding. Якщо ж нам важливі контрольованість та інтерпретованість моделі, особливо при роботі з даними малої розмірності, найкращим вибором буде $(1+\lambda)$-EA with GP encodings, але ця модель потребує значно більшого часу для тренування, в середньому ця модель тренувалась 9.8 годин. 

Якщо ми хочемо збільшити контрольованість і при цьому не витрачати багато часу на тренування, то краще використати алгоритм MLP with single-point mutation, який в середньому тренувався 1.6 хвилину.

Також хочемо окреслити напрямки можливих майбутніх досліджень: необхідно дослідити можливість додання до операції мутації операцію кросинговеру; необхідно дослідити можливість створення мутації під час якої структура дерева не буде фіксованою і будуть змінюватись тільки значення вузлів, а структура дерева буде ініціалізуватися спочатку і під час мутації буде обиратися піддерево та замінюватися на інше піддерево згенероване випадковим чином; необхідно додати прискорення, як тільки моделі MLP with single-point mutation та $(1+\lambda)$-EA with GP encoding виходять на плато, що може значно покращити швидкість навчання та якість моделі. Також варто спробувати приділити певний час для оптимізації бібліотеки Deap, або ж повністю з нуля реалізувати алгоритм $(1+\lambda)$-EA with GP encodings, що також потенційно може значно покращити час навчання цієї моделі.

Додатково, як було зазначено, що $(1+\lambda)$-EA with GP encoding дозволяє фіксувати підерево для збереження відомих залежностей під час навчання, а отже, за аналогією до фізично-інформованих нейронних мереж (англ. PINNs), вказуючи на можливість широкого використання даного підходу.  Тому варто порівняти методи $(1+\lambda)$-EA with GP encoding та PINNs.
