%!TEX root = ../thesis.tex
% створюємо Висновки до всієї роботи
У ході даної роботи ми розглянули теоретичні відомості про задачі класифікації, а саме бінарну та багатокласову класифікацію, а також різні методи їх вирішення. Нами було розглянуто класичні статистичні методи, методи машинного навчання, методи глибинного навчання та генетичні алгоритми, зокрема алгоритм $(1+\lambda)$-EA with GP encodings, для вирішення задач класифікації. Додатково ми розглянули детально процес навчання моделей класифікації та метрики, які використовуються для оцінювання ефективності таких методів.

Було описано інструменти та ресурси, які були використанні для підготовки та проведення дослідження. А саме для реалізації описаних алгоритмів було використано мову програмування Python та бібліотеки Deap та scikit-learn, що забезпечили зручний інтерфейс для налаштування та запуску експериментів, а також інструменти для попередньої обробки даних, побудови та оцінки моделей класифікації. Для аналізу результатів ми обрали три різні набори даних, які представляють різноманітні задачі класифікації.

Також ми розглянули процес попередньої обробки даних, пошуку оптимальних гіперпараметрів та провели експерименти, які продемонстрували плюси та мінуси кожного з роглянутих методів. Було встановлено, що для задач, де важлива швидкість навчання, краще використовувати MLP with gradient descent. Якщо ж нам важливо контрольованість та інтерпретованість моделі, особливо при роботі з даними малої розмірності, кайкращим вибором буде $(1+\lambda)$-EA with GP encodings, але ця модель потребує значно більшого часу для тренування. Якщо ми хочемо збільшити контрольованість і при цьому не витрачати багато часу на тренування, то краще використати алгоритм MLP with single-point mutation.

Також хочемо окреслити напрямки можливих майбутніх досліджень в даній області: перше -- можна спробувати додати до операції мутації також операцію кросинговеру, наприклад батьки можуть окрім як мутувати, схрещуватись змінюючи місцями якісь піддерева між собою, друге -- можна зробити мутацію під час якої структура дерева не буде фіксованою і будуть змінюватись тільки значення вузлів, а структура дерева буде ініціалізуватися спочатку і після цього під час мутації буде обиратися піддерево та замінюватися на інше піддерево згенероване випадковим чином. Також варто спробувати приділити певний час для оптимізації бібліотеки Deap, або ж повністю з нуля реалізувати алгоритм $(1+\lambda)$-EA with GP encodings, що також потенційно може значно покращити час навчання цієї моделі.