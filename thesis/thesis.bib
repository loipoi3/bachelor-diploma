% Encoding: UTF-8

@article{ct1,
	author = {Peng, Joanne and Lee, Kuk and Ingersoll, Gary},
	year = {2002},
	month = {09},
	pages = {3-14},
	title = {An Introduction to Logistic Regression Analysis and Reporting},
	volume = {96},
	journal = {Journal of Educational Research - J EDUC RES},
	doi = {10.1080/00220670209598786}
}

@article{ct2,
	author = {Lipowski, Adam and Lipowska, Dorota},
	year = {2011},
	month = {09},
	pages = {},
	title = {Roulette-wheel selection via stochastic acceptance},
	volume = {391},
	journal = {Physica A: Statistical Mechanics and its Applications},
	doi = {10.1016/j.physa.2011.12.004}
}

@inproceedings{ct3,
	author = {Fang, Yongsheng and li, Jun},
	year = {2010},
	month = {10},
	pages = {181-192},
	title = {A Review of Tournament Selection in Genetic Programming},
	isbn = {978-3-642-16492-7},
	doi = {10.1007/978-3-642-16493-4_19}
}

@InProceedings{ct4,
	author="Guo, Gongde
	and Wang, Hui
	and Bell, David
	and Bi, Yaxin
	and Greer, Kieran",
	editor="Meersman, Robert
	and Tari, Zahir
	and Schmidt, Douglas C.",
	title="KNN Model-Based Approach in Classification",
	booktitle="On The Move to Meaningful Internet Systems 2003: CoopIS, DOA, and ODBASE",
	year="2003",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="986--996",
	abstract="The k-Nearest-Neighbours (kNN) is a simple but effective method for classification. The major drawbacks with respect to kNN are (1) its low efficiency -- being a lazy learning method prohibits it in many applications such as dynamic web mining for a large repository, and (2) its dependency on the selection of a ``good value'' for k. In this paper, we propose a novel kNN type method for classification that is aimed at overcoming these shortcomings. Our method constructs a kNN model for the data, which replaces the data to serve as the basis of classification. The value of k is automatically determined, is varied for different data, and is optimal in terms of classification accuracy. The construction of the model reduces the dependency on k and makes classification faster. Experiments were carried out on some public datasets collected from the UCI machine learning repository in order to test our method. The experimental results show that the kNN based model compares well with C5.0 and kNN in terms of classification accuracy, but is more efficient than the standard kNN.",
	isbn="978-3-540-39964-3"
}

@inproceedings{ct5,
	author = {Durillo, Juan and Nebro, Antonio and Luna, Francisco and Alba, Enrique},
	year = {2009},
	month = {04},
	pages = {183-197},
	title = {On the Effect of the Steady-State Selection Scheme in Multi-Objective Genetic Algorithms},
	volume = {5467},
	isbn = {978-3-642-01019-4},
	journal = {LNCS},
	doi = {10.1007/978-3-642-01020-0_18}
}

@article{ct6,
	author = {Menditto, Antonio and Patriarca, Marina and Magnusson, Bertil},
	year = {2007},
	month = {10},
	pages = {45-47},
	title = {Understanding the meaning of accuracy, trueness and precision},
	volume = {12},
	journal = {Accreditation and Quality Assurance},
	doi = {10.1007/s00769-006-0191-z}
}

@article{ct7,
	author = {Powers, David and Ailab,},
	year = {2011},
	month = {01},
	pages = {2229-3981},
	title = {Evaluation: From precision, recall and F-measure to ROC, informedness, markedness and correlation},
	volume = {2},
	journal = {J. Mach. Learn. Technol},
	doi = {10.9735/2229-3981}
}

@inproceedings{ct8,
	author = {Sokolova, Marina and Japkowicz, Nathalie and Szpakowicz, Stan},
	year = {2006},
	month = {01},
	pages = {1015-1021},
	title = {Beyond Accuracy, F-Score and ROC: A Family of Discriminant Measures for Performance Evaluation},
	volume = {Vol. 4304},
	isbn = {978-3-540-49787-5},
	journal = {AI 2006: Advances in Artificial Intelligence, Lecture Notes in Computer Science},
	doi = {10.1007/11941439_114}
}

@article{ct9,
	title={Adam: A method for stochastic optimization},
	author={Kingma, Diederik P and Ba, Jimmy},
	journal={arXiv preprint arXiv:1412.6980},
	year={2014}
}

@InProceedings{ct10,
	author="Poli, Riccardo
	and Langdon, W. B.",
	editor="Chawdhry, P. K.
	and Roy, R.
	and Pant, R. K.",
	title="Genetic Programming with One-Point Crossover",
	booktitle="Soft Computing in Engineering Design and Manufacturing",
	year="1998",
	publisher="Springer London",
	address="London",
	pages="180--189"
}

@incollection{ct11,
	title = {An Analysis of Multi-Point Crossover},
	editor = {GREGORY J.E. RAWLINS},
	series = {Foundations of Genetic Algorithms},
	publisher = {Elsevier},
	volume = {1},
	pages = {301-315},
	year = {1991},
	issn = {1081-6593},
	doi = {https://doi.org/10.1016/B978-0-08-050684-5.50022-7},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080506845500227},
	author = {William M. Spears and Kenneth A. {De Jong}}
}

@book{ct12,
	title={Applied Logistic Regression},
	author={Hosmer, D.W. and Lemeshow, S.},
	isbn={9780471654025},
	lccn={00036843},
	series={Applied Logistic Regression},
	url={https://books.google.com.ua/books?id=Po0RLQ7USIMC},
	year={2004},
	publisher={Wiley}
}

@article{ct13,
	author = {Guo, Gongde and Wang, Hui and Bell, David and Bi, Yaxin},
	year = {2004},
	month = {08},
	pages = {},
	title = {KNN Model-Based Approach in Classification}
}

@article{ct14,
	author = {Soliman, Tamer and Abd-elaziem, Ayman},
	year = {2023},
	month = {08},
	pages = {},
	title = {A Multi-Layer Perceptron (MLP) Neural Networks for Stellar Classification: A Review of Methods and Results},
	volume = {3},
	journal = {International Journal of Advances in Applied Computational Intelligence},
	doi = {10.54216/IJAACI.030203}
}

@inproceedings{ct15,
	author = {Robu, Raul and Stefan, Holban},
	year = {2011},
	month = {05},
	pages = {52-56},
	title = {A genetic algorithm for classification},
	journal = {Recent Researches in Computers and Computing - International Conference on Computers and Computing, ICCC'11}
}

@inproceedings{ct16,
	title={Bayes and Naive Bayes Classifier},
	author={Vikramkumar and B Vijaykumar and Trilochan},
	year={2014},
	url={https://api.semanticscholar.org/CorpusID:10272111}
}

@article{ct17,
	title={Performance and Classification Evaluation of J48 Algorithm and Kendallâ€™s Based J48 Algorithm (KNJ48)},
	author={N.Sarav anaN and V.Gaya thri},
	journal={International Journal of Computer Trends and Technology},
	year={2018},
	volume={59},
	pages={73-80},
	url={https://api.semanticscholar.org/CorpusID:69700602}
}

@book{ct18,
	author = {Van Rossum, Guido and Drake, Fred L.},
	title = {Python 3 Reference Manual},
	year = {2009},
	isbn = {1441412697},
	publisher = {CreateSpace},
	address = {Scotts Valley, CA}
}

@article{ct19,
	author    = " F\'elix-Antoine Fortin and Fran\c{c}ois-Michel {De Rainville} and Marc-Andr\'e Gardner and Marc Parizeau and Christian Gagn\'e ",
	title     = { {DEAP}: Evolutionary Algorithms Made Easy },
	pages     = { 2171--2175 },
	volume    = { 13 },
	month     = { jul },
	year      = { 2012 },
	journal   = { Journal of Machine Learning Research }
}

@article{ct20,
	title={Scikit-learn: Machine Learning in {P}ython},
	author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
	and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
	and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
	Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	journal={Journal of Machine Learning Research},
	volume={12},
	pages={2825--2830},
	year={2011}
}