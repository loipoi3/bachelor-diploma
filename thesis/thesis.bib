% Encoding: UTF-8

@article{ct1,
	author = {Peng, Joanne and Lee, Kuk and Ingersoll, Gary},
	year = {2002},
	month = {09},
	pages = {3-14},
	title = {An Introduction to Logistic Regression Analysis and Reporting},
	volume = {96},
	journal = {Journal of Educational Research - J EDUC RES},
	doi = {10.1080/00220670209598786}
}

@article{ct2,
	author = {Lipowski, Adam and Lipowska, Dorota},
	year = {2011},
	month = {09},
	pages = {},
	title = {Roulette-wheel selection via stochastic acceptance},
	volume = {391},
	journal = {Physica A: Statistical Mechanics and its Applications},
	doi = {10.1016/j.physa.2011.12.004}
}

@inproceedings{ct3,
	author = {Fang, Yongsheng and li, Jun},
	year = {2010},
	month = {10},
	pages = {181-192},
	title = {A Review of Tournament Selection in Genetic Programming},
	isbn = {978-3-642-16492-7},
	doi = {10.1007/978-3-642-16493-4_19}
}

@InProceedings{ct4,
	author="Guo, Gongde
	and Wang, Hui
	and Bell, David
	and Bi, Yaxin
	and Greer, Kieran",
	editor="Meersman, Robert
	and Tari, Zahir
	and Schmidt, Douglas C.",
	title="KNN Model-Based Approach in Classification",
	booktitle="On The Move to Meaningful Internet Systems 2003: CoopIS, DOA, and ODBASE",
	year="2003",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="986--996",
	abstract="The k-Nearest-Neighbours (kNN) is a simple but effective method for classification. The major drawbacks with respect to kNN are (1) its low efficiency -- being a lazy learning method prohibits it in many applications such as dynamic web mining for a large repository, and (2) its dependency on the selection of a ``good value'' for k. In this paper, we propose a novel kNN type method for classification that is aimed at overcoming these shortcomings. Our method constructs a kNN model for the data, which replaces the data to serve as the basis of classification. The value of k is automatically determined, is varied for different data, and is optimal in terms of classification accuracy. The construction of the model reduces the dependency on k and makes classification faster. Experiments were carried out on some public datasets collected from the UCI machine learning repository in order to test our method. The experimental results show that the kNN based model compares well with C5.0 and kNN in terms of classification accuracy, but is more efficient than the standard kNN.",
	isbn="978-3-540-39964-3"
}
